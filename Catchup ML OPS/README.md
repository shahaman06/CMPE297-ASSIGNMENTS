# Catchup Assignments for Quizzes

**Description**:<br/><br/>
I have utilized OpenAI GPT2 generative model, using transformers library provided by huggingface. OpenAI GPT2 is one of renowned large transformer-based language transformer with 1.5 billion parameters. The model being used here is GPT2LMHeadModel, instead of GPT2MODEL cause the first provides us with a language modeling head on top. I have also directly utilized pretrained weights for faster text generation and utilize GPU in Colab notebook to reduce training time.

<br/>

**Colab Link**: https://colab.research.google.com/drive/1Tpht1rU0cheO1ggXQHc3-KB_6wRQxozR?usp=sharing